% !TeX root = main.tex
%===================================== CHAP 4 =================================

\chapter{B-spline MINMPC}\label{chap:b-spline-minmpc}

\section{Dynamic Model}
\subsection{Double Integrator}\label{sec:double-integrator}
The double integrator model is a simple model that ensures a continuous position, velocity, and acceleration for the ship. The model is described by the following equations:
\begin{subequations}\label{eq:double-integrator}
    \begin{align}
        \dot{\mathbf{p}}(t) &= \mathbf{v}(t), \label{eq:double-integrator-x} \\
        \dot{\mathbf{v}}(t) &= \mathbf{a}(t), \label{eq:double-integrator-v} \\
        \|\mathbf{v}(t)\|_2 &\leq v_{\max}, \label{eq:double-integrator-vmax} \\
        \|\mathbf{a}(t)\|_2 &\leq a_{\max}, \label{eq:double-integrator-a}
    \end{align}
\end{subequations}
where $\mathbf{p} = [p_N, p_E]^\top$ denotes the position of the ship, $\mathbf{v} = [v_N, v_E]^\top$ is the velocity, and $\mathbf{a} = [a_N, a_E]^\top$ is the acceleration in North-East coordinates. The $\|\cdot\|_2$ notation denotes the Euclidean norm, and $v_{\max}$ and $a_{\max}$ are the maximum speed and acceleration of the ship, respectively.

This continuous model can be relaxed to a B-spline model by letting $\mathbf{p}(x)$, $\mathbf{v}(x)$, and $\mathbf{a}(x)$ be spline functions on a chosen B-spline basis. It is desirable to let time be a variable in the optimization problem so that minimum time trajectories can be found. It is impractical to let the knot values of the B-spline representation of $\mathbf{p}(x)$ be optimization variables as an analysis of the Cox-de Boor recursion formula in \cref{eq:b-spline-recurrence} shows that the spline function is non-linear in these knot values. More specifically a degree $p$ B-spline with the parameter $x$ fixed, will be a polynomial of degree $p$ in the knot values. Instead, the time variable $t$ is introduced as a function of the parameter $x$, which is a common approach in these types of problems \citep{mercy2017spline,ShortestPathsConvexSets}. 

With this approach, the velocity and acceleration can now be expressed as
\begin{subequations}\label{eq:double-integrator-spline}
    \begin{align}
        \mathbf{v}(t) &= \frac{\partial \mathbf{p}}{\partial x} \frac{\partial x}{\partial t} = \frac{\mathbf{p}'}{t'},
        \label{eq:double-integrator-v-spline} \\
        \mathbf{a}(t) &= \frac{\partial \mathbf{v}}{\partial t} = \frac{\partial}{\partial t} \left(\frac{\mathbf{p}'}{t'}\right) = 
        \frac{
            t'\frac{\partial \mathbf{p}'}{\partial t} - \mathbf{p}'\frac{\partial t'}{\partial t}
            }{(t')^2} = 
        \frac{\mathbf{p}'' - \mathbf{p}'\frac{t''}{t'}}{(t')^2}.
        \label{eq:double-integrator-a-spline}
    \end{align}
\end{subequations}
Here $(\cdot)'$ and $(\cdot)''$ denotes the first and second derivative with respect to the spline parameter $x$, respectively. In \cref{eq:double-integrator-spline}, the inverse function theorem was used to flip the relation between $t$ and $x$. This is only possible if $t$ is a strictly increasing function of $x$, which is the case if the constraint 
\begin{equation}\label{eq:constraint-t}
    t'(x) > 0
\end{equation}
holds.  
If we in addition require the time to be positive, the velocity constraint in \cref{eq:double-integrator-vmax} becomes
\begin{equation}\label{eq:double-integrator-vmax-spline}
    \begin{aligned}
        &&\|\mathbf{v}(t)\|_2 = \left\|\frac{\mathbf{p}'}{t'}\right\|_2 &\leq v_{\max} \\
        &\implies& \|\mathbf{p}'(x)\|_2 &\leq t'(x)v_{\max} \\
        &\implies& \mathbf{p}'(x)\cdot\mathbf{p}'(x) &\leq (t'(x))^2v_{\max}^2.
    \end{aligned}
\end{equation}
To simplify the model, yet another restriction is put on the time function $t(x)$ by requiring it to be a 1st degree B-spline function. This means that the time variable is a piecewise linear function of the parameter $x$, and the second derivative of $t$ is zero, giving the simplified acceleration constraint
\begin{equation}\label{eq:double-integrator-a-spline-simplified}
    \begin{aligned}
        &&\|\mathbf{a}(t)\|_2 = \left\|\frac{\mathbf{p}''}{(t')^2}\right\|_2 &\leq a_{\max} \\
        &\implies& \|\mathbf{p}''(x)\|_2 &\leq t'(x)^2a_{\max} \\
        &\implies& \mathbf{p}''(x)\cdot\mathbf{p}''(x) &\leq t'(x)^4a_{\max}^2.
    \end{aligned}
\end{equation}

Now the B-Spline relaxation is fully given by the following equations:
\begin{subequations}\label{eq:double-integrator-spline-complete}
    \begin{align}
        \mathbf{p}(x) &= \sum_{i=0}^{n} \mathbf{p}_i B_{i,p,\mathbf{t}}(x), \label{eq:double-integrator-spline-complete-p} \\
        t(x) &= \sum_{i=0}^{m} t_i B_{i,1,\boldsymbol{\tau}}(x), \label{eq:double-integrator-spline-complete-t} \\
        \mathbf{p}'(x) \cdot \mathbf{p}'(x) &\leq t'(x)^2v_{\max}^2, \label{eq:double-integrator-spline-complete-vmax} \\
        \mathbf{p}''(x) \cdot \mathbf{p}''(x) &\leq t'(x)^4a_{\max}^2, \label{eq:double-integrator-spline-complete-a} \\
        t(x) &\geq 0, \label{eq:double-integrator-spline-complete-t-constraint} \\
        t'(x) &> 0. \label{eq:double-integrator-spline-complete-t-derivative} \end{align}
\end{subequations}
The only optimization variables needed are the B-Spline coefficients $\mathbf{p}_i\in\mathbb{R}^2$ and $t_i\in\mathbb{R}^+$ from \cref{eq:double-integrator-spline-complete-p,eq:double-integrator-spline-complete-t}, which are subject to the constraints \cref{eq:double-integrator-spline-complete-vmax,eq:double-integrator-spline-complete-a,eq:double-integrator-spline-complete-t-constraint,eq:double-integrator-spline-complete-t-derivative}.


\subsection{Dubins Model}\label{sec:dubins-model}
\todo{Legg til tid på samme måte som i dobbeltintegratormodellen}

The double integrator model is a simple model that ensures a continuous position, velocity, and acceleration for the ship. However, it does not take into account the ship's heading and turning radius. Dubins model (also referred to as the unicycle model) is a more realistic model for ship dynamics, as it describes a vehicle moving in a plane where the velocity points in the direction of the heading. In the motion control literature, there exists a variety of parameterizations for this kind of model. Notably \citet{mercy2017spline}, which uses the tangent half-angle substitution to represent the heading angle in a B-spline framework and \citet{Wang2020}, which uses a convex relaxation technique with sequential convex programming to exchange nonlinear equality constraints with convex inequalities. 

The model in \cite{Wang2020} technique was discarded as the assumtions for the relaxation technique are not valid under a reference following scenario. \cite{mercy2017spline} used the tangent half-angle to parameterize the bicycle model, which also includes the steering angle as a control input. In this work, the simplified Dubins model was tested, but ultimately discarded as the Pythogerean-hodograph (PH) B-spline model has the same properties as the tangent half-angle model, but has in addition all the nice properties described in \cref{sec:pythogerean-hodograph}. See \cref{app:tangent-half-angle} for a more detailed description of the Dubins model and the tangent half-angle substitution.

Dubins model can be described by the following equations:
\begin{subequations}\label{eq:dubins-model}
    \begin{align}
        \dot p_N &= V \cos(\chi),       \label{eq:dubins-x} \\
        \dot p_E &= V \sin(\chi),       \label{eq:dubins-y} \\
        \dot \chi &= \omega,          \label{eq:dubins-chi} \\
        |\omega| &\leq \omega_{\max}, \label{eq:dubins-omega} \\
        0 \leq V &\leq V_{\max},      \label{eq:dubins-V} 
    \end{align}
\end{subequations}
where $p_N$ and $p_E$ are the North and East position coordinates of the ship, and $\chi$ is the heading angle. The control input is the speed $V$ and turn rate $\omega$. Using the PH B-spline model from \cref{sec:pythogerean-hodograph}, the Dubins model can be expressed as
\begin{subequations}\label{eq:dubins-model-ph}
    \begin{align}
        \dot p_N(x) &= u(x)^2 - v(x)^2, \label{eq:dubins-ph-x} \\
        \dot p_E(x) &= 2u(x)v(x),       \label{eq:dubins-ph-y} \\
        \dot \chi(x) &= \omega(x) = \frac{2\big(u(x)v'(x) - u'(x)v(x)\big)}{u(x)^2 + v(x)^2},  \label{eq:dubins-ph-chi} \\
        |\omega(x)| &\leq \omega_{\max},  \\
        V(x) &= u(x)^2 + v(x)^2 \\
        0 \leq V(x) &\leq V_{\max}, 
    \end{align}
\end{subequations}
where \cref{eq:dubins-ph-x,eq:dubins-ph-y} correspond to \cref{eq:hodograph-derivatives-a,eq:hodograph-derivatives-b} and \cref{eq:dubins-ph-chi} follows from \cref{eq:turn-rate}.

To implement this model in an optimization framework, $u(x)$ and $v(x)$ are represented as B-spline functions, and the turn-rate constraints are derived as follows
\begin{equation*}
    \begin{aligned}
        |\omega(x)| &\le \omega_{\max} \\
        \implies \left|\frac{2\big(u(x)v'(x) - u'(x)v(x)\big)}{u(x)^2 + v(x)^2}\right| &\le \omega_{\max} \\
        \implies \left|u(x)v'(x) - u'(x)v(x)\right| &\le \frac{\omega_{\max}}{2}\left(u(x)^2 + v(x)^2\right),
    \end{aligned}
\end{equation*}
yeilding the polynomial constraints
\begin{subequations}\label{eq:dubins-ph-turn-rate}
    \begin{align}
        u(x)v'(x) - u'(x)v(x) &\le \frac{\omega_{\max}}{2}\left(u(x)^2 + v(x)^2\right), \\
        u(x)v'(x) - u'(x)v(x) &\ge -\frac{\omega_{\max}}{2}\left(u(x)^2 + v(x)^2\right).
    \end{align}
\end{subequations}

The constraint in \cref{eq:dubins-ph-chi} is a rational B-spline function and could in theory be implemented as a NURBS directly in an optimization framework. However, this is not done as unlike the bilinear terms in \cref{eq:dubins-ph-turn-rate}, the rational term in \cref{eq:dubins-ph-chi} has a singularity when $u(x)$ and $v(x)$ are both zero.


\section{Target Ships}
\todo{skriv introduksjon til dette avsnittet}

\subsection{Hyperplane Separation Theorem}
The standard way to enforce collision constraints between the OS and TS is to apply a minumum distance constraint between the two ships as
\begin{equation}\label{eq:minimum-distance}
    (\mathbf p_{\text{OS}} - \mathbf p_{\text{TS}}) \cdot (\mathbf p_{\text{OS}} - \mathbf p_{\text{TS}}) \geq d_{\text{min}}^2,
\end{equation}
where $\mathbf p_{\text{OS}}$ and $\mathbf p_{\text{TS}}$ are the positions of the OS and TS, respectively, and $d_{\text{min}}$ is the minimum distance between the two ships. Examples of this type of constraint can be found in \cite{Thyri2022-MPC}.\todo{flere kilder} This constraint is non-convex, as the feasible region for the OS lies outside the circle with radius $d_{\text{min}}$ centered at the TS.

Another method of enforcing collision avoidance is to use the hyperplane separation theorem. Although still non-convex, this method allows for a more flexible formulation of the constraint, as it is not only restricted to circular shapes. 
The hyperplane separation theorem states that for two disjoint convex sets $\mathcal A$ and $\mathcal B$, there exists $\mathbf n\in \mathbb R^n\backslash\{\mathbf0\}$ and $b\in\mathbb R$ such that the hyperplane $H=\{\mathbf x\in\mathbb R^n \mid \mathbf n^\top \mathbf x = b\}$ separates $\mathcal A$ and $\mathcal B$ \citep{Boyd2004-ih}. In other words, there exists a function $a^\top x - b$ that is non-negative for all $x \in \mathcal A$ and non-positive for all $x \in \mathcal B$. 

Using this theorem, the collision avoidance task can be transformed to a classification problem. The objective is to find a line that separates the OS and TS, such that the distance between the line and the ships is greater than a given threshold. This is done in the B-spline framework by introducing a hyperplane $\mathcal H$ with normal $\mathbf n(t)\in\mathbb{S}^2_{p,\mathbf t}$ and offset $b(t)\in\mathbb{S}_{p,\mathbf t}$, which separates the OS and TS. This hyperplane is implemented using the following constraints:
\begin{subnumcases}{\label{eq:minimum-distance-hyperplane}\mathcal{H}:}
    \mathbf p_\text{OS}(t) \cdot{\mathbf n}(t) & $\ge b(t) + d_\text{OS}$,
    \label{eq:hyperplane-os} \\
    \mathbf p_\text{TS}(t) \cdot{\mathbf n}(t) & $\le b(t) - d_\text{TS}$,
    \label{eq:hyperplane-ts} \\
    \|{\mathbf n}(t)\|_\infty & $\le 1$.
    \label{eq:hyperplane-norm}
\end{subnumcases}
The constraints in \zcref{eq:hyperplane-os,eq:hyperplane-ts} are enforced by
letting $\mathbf n(t)$ and $b(t)$ be optimization variables. Equation \zcref{eq:hyperplane-norm} is a box constraint on $\mathbf n(t)$, ensuring that the hyperplane normal doesn't become too large. The minimum distance constraint in \cref{eq:minimum-distance} can be equivalently expressed using the hyperplane separation theorem by letting $d_\text{OS} = 0$ and $d_\text{TS} = d_\text{min}$ in \zcref{eq:hyperplane-os,eq:hyperplane-ts}. As the following section shows,

\subsection{Collision Constraints}\label{sec:collision-constraints}

Collision avoidance is non-convex: with fixed start/end points one cannot deform a trajectory from one side of the obstacle to the other without intersection. A convex solver will therefore remain on the same side (see \cref{fig:non-convex-obstacle}), potentially missing the globally optimal path.
\begin{figure}
    \centering
    \includesvg[width=0.8\textwidth]{fig/b-spline/non-convex-obstacle.svg}
    \caption{Black dots: fixed start/end points. Dotted line: current trajectory. Solid line: reference. Red circle: obstacle. A convex solver cannot switch sides without violating the obstacle constraint.}
    \label{fig:non-convex-obstacle}
\end{figure}

For designing a COLREGS-compliant trajectory, being able to decide which side of a given target ship to pass on is essential. So to address the aforementioned issue, which side to pass the obstacle on is made a decision variable in a mixed integer programming (MIP) problem as follows:

The idea is that each target ship is represented by two obstacles, each obstacle having only one feasible side to be passed on. The passing side of the target ship is enforced by adding additional points to each obstacle on the opposide side of the passing side using the normal $\mathbf{\hat n}_\text{ref}$ of the reference trajectory $\mathbf p_\text{ref}$. The two obstacles are then moved into and out of the feasible region by introducing a binary variable $z_j\in\{0,1\}$ for each target ship $j$ which controls an offset $M \mathbf{\hat n}_\text{ref}$, where $M$ is a large positive number. More formally, the constraints are given by

\begin{subnumcases}{\label{eq:colregs-bigM}\mathcal{O}_j:}
    \mathbf{n}_{p,j}(t)\cdot\mathbf{p}_{\mathrm{OS}}(t)
      & \label{eq:colregs-bigM-os-p}$\ge b_{p,j}(t) + d_{\text{OS}}$\\
    \mathbf{n}_{p,j}(t)\cdot\mathbf{p}_{\mathrm{TS},j}(t)
      & \label{eq:colregs-bigM-ts-p}$\le b_{p,j}(t) - d_{\text{TS},j} + M\,z_j$\\
    \mathbf{n}_{p,j}(t)\cdot\bigl(\mathbf{p}_{\mathrm{TS},j}(t)+2M\,\mathbf{\hat n}_{\mathrm{ref}}(t)\bigr)
      & \label{eq:colregs-bigM-ts-o-p}$\le b_{p,j}(t) - M$\\[1.5ex]
      %
    \mathbf{n}_{s,j}(t)\cdot\mathbf{p}_{\mathrm{OS}}(t)
      & \label{eq:colregs-bigM-os-s}$\ge b_{s,j}(t) + d_{\text{OS}}$\\
    \mathbf{n}_{s,j}(t)\cdot\mathbf{p}_{\mathrm{TS},j}(t)
      & \label{eq:colregs-bigM-ts-s}$\le b_{s,j}(t) - d_{\text{TS},j} + M\,(1-z_j)$\\
    \mathbf{n}_{s,j}(t)\cdot\bigl(\mathbf{p}_{\mathrm{TS},j}(t)-2M\,\mathbf{\hat n}_{\mathrm{ref}}(t)\bigr)
      & \label{eq:colregs-bigM-ts-o-s}$\le b_{s,j}(t) - M$\\[1.5ex]
    z_j \in \{0,1\} & \label{eq:colregs-bigM-z} \\
    \|\mathbf{n}_{p,j}(t)\|_\infty\le 1 & \label{eq:colregs-bigM-np} \\
    \|\mathbf{n}_{s,j}(t)\|_\infty\le 1 & \label{eq:colregs-bigM-ns}
\end{subnumcases}
    
Here,
\begin{itemize}
    \item $\mathbf{n}_{p,j}(t)$ and $b_{p,j}(t)$ are the port‐side hyperplane normal and offset,
    \item $\mathbf{n}_{s,j}(t)$ and $b_{s,j}(t)$ are the starboard‐side normal and offset,
    \item $d_{\text{OS}}$ and $d_{\text{TS},j}$ are the required minimum separations for the OS and TS from the hyperplane, 
    \item $z_j\in\{0,1\}$ selects port‐side ($z_j=0$) or starboard‐side ($z_j=1$) passage,
    \item $\mathbf{p}_{\mathrm{TS},j}(t)+2M\,\mathbf{\hat n}_{\mathrm{ref}}(t)$ and $\mathbf{p}_{\mathrm{TS},j}(t)-2M\,\mathbf{\hat n}_{\mathrm{ref}}(t)$ are the two obstacles on the opposite side of the passing side,
    \item $M$ is a large constant that renders inactive constraints nonbinding.
    \item and $\mathbf{\hat n}_{\mathrm{ref}}(t)$ is the unit normal of the reference trajectory $\mathbf p_\text{ref}(t)$, defined as
    \begin{equation}\label{eq:reference-normal}
        \mathbf{\hat n}_{\mathrm{ref}}(t) = \mathbf R\frac{\mathbf p_\text{ref}'(t)}{\|\mathbf p_\text{ref}'(t)\|_2}.
    \end{equation}
    where $\mathbf R$ is a rotation matrix that rotates 90 degrees counterclockwise around the down axis in a North-East-Down coordinate system.
\end{itemize}
The first three inequalities
(\zcref{eq:colregs-bigM-os-p,eq:colregs-bigM-ts-p,eq:colregs-bigM-ts-o-p})
apply when passing on the port side, while the last three
(\zcref{eq:colregs-bigM-os-s,eq:colregs-bigM-ts-s,eq:colregs-bigM-ts-o-s})
enforce the starboard‐side conditions.


Including all ships’ constraints $\mathcal{O}_j$ guarantees that a passing side is chosen for each TS and that the required separation is maintained.
    
In the NLP relaxation of the MINLP (letting $z_j$ be continuous), there is now a way to continuously move the trajectory from one side of the obstacle to the other without violating any constraints. To be clear, all of the obstacles and points are active at the same time, but with a large enough chosen constant $M$, the inactive obstacles are so far away from the trajectory that they do not affect the optimization problem. This strategy is commonly referred to as the big-M method in Mixed Integer Programming (MIP) literature \citep{gan2012adaptive,Cococcioni2020}.

\begin{figure}
    \centering
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includesvg[width=\textwidth,pretex=\scriptsize]{fig/b-spline/non-convex-obstacle-mi-sb.svg}
        \caption{Starboard maneuver ($z_j=1$)}
        \label{fig:non-convex-obstacle-mi-sb}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includesvg[width=\textwidth,pretex=\scriptsize]{fig/b-spline/non-convex-obstacle-mi-port.svg}
        \caption{Port maneuver ($z_j=0$)}
        \label{fig:non-convex-obstacle-mi-port}
    \end{subfigure}
    \caption{Visualization of the Big–$M$ collision-avoidance constraints in \cref{eq:colregs-bigM}: the top panel shows a starboard maneuver and the bottom panel a port maneuver. The red/orange polygon represents the target ship (TS) and the blue polygon the own ship (OS). Grey areas indicate infeasible regions (not to scale). The solid line denotes the reference trajectory, while the dashed line depicts the planned trajectory under the current optimization variables.}
    \label{fig:non-convex-obstacle-mi}
\end{figure}



\section{Objective Function}
The goals of the objective function should be 1) to find a safe, COLREGS-compliant trajectory, and 2) to follow a reference trajectory. These objectives are conflicting as rule 8b) of the COLREGS (see \cref{sec:colregs}) states that any alteration of course should be large enough to be readily apparent to another vessel. Following a reference trajectory on the other hand often involves the squared error between the vessel and the reference trajectory, which inherently penalizes sudden deviations in course. 
Thus a careful choice of the objective function is important to ensure robust and predictable behaviour. 
The following section will examine the behavior of the B-spline method when applied to a basic reference-following task. The subsequent section will then address COLREGS considerations.


\subsection{Reference Following}
\label{sec:oscillations}


\begin{figure}
    \centering
    \includesvg[width=0.8\textwidth]{fig/illustrations/cross-track- and along-track- error.svg}
    \caption{Cross-track error and total track error for a vessel trying its best to follow a reference trajectory. Figure adapted from \cite{prosjektoppgave}.}
    \label{fig:cross-track-along-track-error}
\end{figure}

Literature on motion planning distinguishes between path following, where only geometric relations are considered, and trajectory following, which considers both geometric and temporal relations. 
Path following is often expressed in terms of the cross-track error (XTE) \citep{Fossen2011-Handbook}. The XTE is the closest distance between the \acrshort{OS} and the reference path. In reactive methods such as pure pursuit and line-of-sight guidance, the XTE is used to determine the steering angle of the \acrshort{OS} at any given time \citep{Fossen2011-Handbook}. 
Using these costs in motion planning problems, where the entire trajectory is considered, is not straightforward. Depending on the geometry of the reference trajectory, the XTE can be a non-convex function of the OS position. This also holds true in the B-spline framework, where numerical search methods are generally needed to compute the closest distance from a point to a spline \citep{johnson2005distance,hu2005second,chen2009computing}.

The \acrfull{TTE} will now be defined as the distance between a time parameterized OS and a time parameterized reference trajectory. This is a more practical cost function, as now only a distance between two points is considered at any given time. The TTE between the position of the OS $\mathbf p_\text{os}(t)$ and the position of the reference trajectory $\mathbf p_\text{ref}(t)$ is given by
\begin{equation}\label{eq:total-track-error}
    \mathbf e(t) = \mathbf p_\text{os}(t) - \mathbf p_\text{ref}(t).
\end{equation}

In classical optimal control with time grids, the simplest way to design an objective function is to minimize the sum of the squared TTE at each time step, i.e., to minimize
\begin{equation*}
    \sum_{k=0}^{N_t} \|\mathbf e(t_k)\|_2^2,
\end{equation*}
where $t_k$ is the time at the $k$-th time step and $N_t$ is the number of time steps. 

A similar approach can be used in the B-spline framework, where both the OS and the reference trajectory are represented as B-spline functions. The TTE cost function can then be expressed as the integral over the squared TTE, i.e., to minimize
\begin{equation}\label{eq:total-track-error-b-spline}
J_\text{ref} = \int_\mathbb R \mathbf e(x) \cdot \mathbf e(x) \, dx =  \|\mathbf e(x)\|_G^2,
\end{equation}
where $\mathbf e(x) = \mathbf p_\text{os}(x) - \mathbf p_\text{ref}(x)$ represents the TTE at parameter $x$, and the integral is evaluated across the B-spline functions' parameter domain. However, this work revealed that the overlapping support of B-spline basis functions can induce oscillations in the resulting trajectory when employing this cost function directly (see \cref{fig:conservativeness-traj-integral}). Therefore, careful consideration is required when designing this cost within the B-spline framework.

To illustrate this, consider the following optimization problem, which is a simple reference-following problem where the OS is constrained to a maximum velocity $v_\text{max}$:
\begin{equation}\label{eq:conservativeness-optimization}
    \begin{aligned}
        \min_{\mathbf c} \quad & J_\text{ref} \\
        \text{subject to} \quad &\mathbf p_\text{os}(0) = \mathbf p_0, \\
                    &\mathbf p_\text{os} = \mathbf B^\top(x) \mathbf c, \\
                    &\mathbf p_\text{ref} = \mathbf B_\text{ref}^\top(x) \mathbf c_\text{ref}, \\
                    & \mathbf p_\text{os}'(x) \cdot \mathbf p_\text{os}'(x) \le v_\text{max}^2.
    \end{aligned}
\end{equation}
Here, $\mathbf p_0$ is the initial position of the OS and the $\cdot$ operator denotes the pointwise dot product as described in \cref{sec:b-spline-theory}. The B-spline basis functions $\mathbf B$ and $\mathbf B_\text{ref}$ are defined as uniform B-splines of degree $p$ and 1, respectively, with the parameter domain $x\in[0,1]$. The control points $\mathbf c$ of the OS B-spline function are optimized to minimize the TTE to a reference trajectory $\mathbf p_\text{ref}$, which is defined by the control points $\mathbf c_\text{ref}$.
This optimization problem is then analyzied for different choices of $p$ and number $N$ of uniform B-spline basis functions $\mathbf B$. The resulting trajectories are shown in \cref{fig:conservativeness} with the parameters for the optimization problem set to
\begin{equation}\label{eq:conservativeness-parameters}
    \begin{aligned}
        \mathbf p_0 &= \begin{bmatrix} 1 & 0 \end{bmatrix} \\
        \mathbf B &= \mathbf B_{p, \mathbf u(p,n)} \\
        \mathbf B_\text{ref} &= \mathbf B_{1,\{0, 0, 1, 1\}} \\
        \mathbf c_\text{ref} &= \begin{bmatrix}
            [0 & 0] \\
            [0 & 3]
        \end{bmatrix} \\
        v_\text{max} &= 6, \\
    \end{aligned}
\end{equation}
where $\mathbf u(p,n) = \{\{0\}^{(p)}, \{i/N\}_{i=0}^{N}, \{1\}^{(p)}\}$ is a function that generates the knot vector for a uniform B-spline of degree $p$ with $N$ basis functions. The resulting trajectories are shown in \cref{fig:conservativeness-traj-integral}.

% $\|\cdot\|_\text{F}^2$ is the squared Frobenius norm, given by
% \begin{equation}
%     \|\mathbf A\|_\text{F}^2 = \sum_{i,j} a_{ij}^2,
% \end{equation}
% where $\mathbf A$ is a matrix and $a_{ij}$ is the element in the $i$-th row and $j$-th column of $\mathbf A$. All other operations on the B-spline functions are done using the algorithms in \cref{sec:b-spline-theory}. 


\begin{figure}
    % \centering
    % \begin{subfigure}[b]{\textwidth}
    % \centering
    % \includesvg[width=\textwidth]{fig/conservativeness/conservativeness_traj_coeffs_degree_3.svg}
    %     \caption{Discrete cost: Trajectory using the sum of squared coefficients of the reference error as a cost function.}
    %     \label{fig:conservativeness-traj-coeffs}
    % \end{subfigure}
    % \hfill
    % \begin{subfigure}[b]{\textwidth}
    %     \centering
        \includesvg[width=\textwidth]{fig/conservativeness/conservativeness_traj_integral_degree_3.svg}
        \caption{Optimal trajectory in \cref{eq:conservativeness-optimization} with parameters \cref{eq:conservativeness-parameters} for $N\in\{4,\ldots,20\}$.}
        \label{fig:conservativeness-traj-integral}
    % \end{subfigure}
    % \caption{Comparison of optimal trajectory in \cref{eq:conservativeness-optimization} with parameters \cref{eq:conservativeness-parameters} for $N\in\{4,\ldots,20\}$.}
    % \label{fig:conservativeness-traj}
\end{figure}

The oscillatory behavior observed in \cref{fig:conservativeness-traj-integral} can be attributed to the integral cost function's emphasis on the global trajectory shape, which consequently diminishes its sensitivity to high-frequency oscillations. To substantiate this claim, and to find a solution to the problem, a rigorous analysis of the eigenvectors and eigenvalues of the Hessian matrix associated with this cost function will be conducted.

To find the Hessian of the cost function, one can observe that the integral of the squared error can be expressed as a quadratic form in the coefficients of the B-spline functions. The cost function can be rewritten as
\begin{equation}
    \begin{aligned}
        J_\text{ref} &= \|\mathbf e(x)\|_G^2 \\
        &= \int_\mathbb R \sum_i \mathbf c_{\mathbf e,i}^\top \mathbf B(x) \mathbf B^\top(x) \mathbf c_{\mathbf e,i}  dx \\
        &= \sum_i \mathbf c_{\mathbf e,i}^\top \underbrace{\int_\mathbb R \mathbf B(x) \mathbf B^\top(x) dx}_{\mathbf G} \;\mathbf c_{\mathbf e,i},
    \end{aligned}
\end{equation}
where $\mathbf c_{\mathbf e,i}$ are the coefficients of the B-spline function $\mathbf e(x)$, which represents the TTE. The subscript $i\in\{N,E\}$ denotes the North and East components of the position error, respectively.
The basis $\mathbf B(x)$ is the same as for $\mathbf p_\text{os}(x)$ as $\mathbf B_\text{ref} \subseteq \mathbf B$ using the parameters in \cref{eq:conservativeness-parameters}. 
The integral $\int_\mathbb R \mathbf B(x) \mathbf B^\top(x) dx$ results in a matrix $\mathbf G$, known in the literature as the Gramian of the B-spline basis, and hereafter referred to simply as the Gramian (see \citet{Chu2022} for a more detailed description).
The Gramian matrix is an important mathematical object in the literature with one of its defining properties being that it is always positive semi-definite \citep{horn2013positive}. However, with our choice of basis functions with restrictions on knot multiplicality, the Gramians considered in this work will always be symmetric and strictly positive definite, i.e., all eigenvalues real and positive. 

Using the spectral (eigenvalue) decomposition of the Gramian $\mathbf G = \mathbf U \mathbf \Lambda \mathbf U^\top$, the cost function can be expressed differently. Here, $\mathbf U$ is a matrix whose columns are the unit-normalized eigenvectors of $\mathbf G$, and $\mathbf \Lambda$ is a diagonal matrix with the eigenvalues of $\mathbf G$ on the diagonal. Thus, the cost function can be rewritten as
\begin{equation}\label{eq:cost-function-spectral-decomposition}
    J_\text{ref} = \sum_i \mathbf c_{\mathbf e,i}^\top \mathbf G \mathbf c_{\mathbf e,i} = \sum_i \mathbf c_{\mathbf e,i}^\top \mathbf U \mathbf \Lambda \mathbf U^\top \mathbf c_{\mathbf e,i} = \sum_i \sum_{j=1}^{N} \lambda_j (\mathbf u_j^\top \mathbf c_{\mathbf e,i})^2,
\end{equation}
where $\lambda_j$ is the $j$-th eigenvalue of $\mathbf G$ and $\mathbf u_j$ is the $j$-th eigenvector of $\mathbf G$. With the cost function in this form, it is clear that the cost is a weighted sum of the squared projections of the coefficients $\mathbf c_{\mathbf e,i}$ onto the eigenvectors $\mathbf u_j$ of the Gramian $\mathbf G$. The eigenvalues $\lambda_j$ determine the weight of each projection, and thus the cost function penalizes the coefficients more heavily if they have a matching projection onto an eigenvector with a large eigenvalue.

As an example, consider the Gramian $\mathbf G_{2,\mathbf u(2,4)}$ for a uniform B-spline basis of degree $p=2$ with $N=4$ can be computed using the relevant formulas in \cref{sec:b-spline-theory} to yield
\begin{equation}
    \mathbf G_{2,\mathbf u(2,4)} = \int_\mathbb R \mathbf B_{2,\mathbf u(2,4)}(x) \mathbf B_{2,\mathbf u(2,4)}^\top(x) dx = 
    \frac{1}{120}\begin{bmatrix}
        12 & 7 & 1 & 0 \\
        7 & 20 & 12 & 1 \\
        1 & 12 & 20 & 7 \\
        0 & 1 & 7 & 12
    \end{bmatrix}.
\end{equation}

This matrix has the eigenvectors 
\begin{equation}
    \begin{aligned}
        \mathbf u_1 &\approx \begin{bmatrix}  
            0.23 \\  0.67 \\  0.67 \\  0.23 
        \end{bmatrix}, &
        \mathbf u_2 &\approx \begin{bmatrix}         
            0.57 \\  0.41, \\ -0.41 \\  -0.57 
        \end{bmatrix}, &
        \mathbf u_3 &\approx \begin{bmatrix}         
            0.67 \\  -0.23 \\  -0.23 \\  0.67 
        \end{bmatrix}, &
        \mathbf u_4 &\approx \begin{bmatrix}         
            0.41 \\  -0.57 \\  0.57 \\  -0.41 
        \end{bmatrix},
    \end{aligned}
\end{equation}
with corresponding eigenvalues
\begin{equation}
    \begin{aligned}
        \lambda_1 &\approx 0.29, &
        \lambda_2 &\approx 0.14, &
        \lambda_3 &\approx 0.07. &
        \lambda_4 &\approx 0.03.
    \end{aligned}
\end{equation}
The $u_1$ direction can be interpreted as a direction where all the coefficients have the same sign, while the $u_4$ direction can be interpreted as a direction where subsequent coefficients alternate in sign. 
As the cost in the $u_1$ direction compared to the $u_4$ direction is $\frac{\lambda_1}{\lambda_4} \approx 10$ times smaller, the cost function will amplify high frequency oscillations in the coefficients, which explains the behaviour in \cref{fig:conservativeness-traj-integral}. In \cref{fig:conservativeness-eigenvectors}, each eigenvector is shown as a weight on each B-spline coefficient where \cref{fig:conservativeness-eigenvectors-integral} shows the situation for the above example.
\Cref{fig:conservativeness-eigenvectors-coeffs,fig:conservativeness-eigenvectors-inv-gramian} show the eigenvectors for when the cost is set to $\mathbf c^T \mathbf H \mathbf c$ with $\mathbf H = \mathbb I$ and $\mathbf H = \mathbf G^{-1}$, respectively.




\begin{figure}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includesvg[width=\textwidth,pretex=\small]{fig/conservativeness/eigenvectors_integral_degree_2_N_4.svg}
        \caption{$\mathbf H = \mathbf G$}\label{fig:conservativeness-eigenvectors-integral}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \centering
        \includesvg[width=\textwidth,pretex=\small]{fig/conservativeness/eigenvectors_coeffs_degree_2_N_4.svg}
        \caption{$\mathbf H = \mathbb{I}$}\label{fig:conservativeness-eigenvectors-coeffs}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \centering
        \includesvg[width=\textwidth,pretex=\small]{fig/conservativeness/eigenvectors_inv_gramian_degree_2_N_4.svg}
        \caption{$\mathbf H = \mathbf G^{-1}$}\label{fig:conservativeness-eigenvectors-inv-gramian}
    \end{subfigure}
    \caption{Eigenvectors of the Hessian $H$ of the cost function for the continuous cost function (top), discrete cost function (middle) and the inverse Gramian matrix (bottom) for $N=4$ and $p=2$. Note that $\hat\lambda$ is a scaled version of the eigenvalues $\lambda$ such that $\hat\lambda_i = \lambda_i/\sum_{i=1}^{N} \lambda_i$}
\label{fig:conservativeness-eigenvectors}
\end{figure}


Reviewing the results in \cref{fig:conservativeness-traj-integral}, it is clear that the discrete cost function is much more conservative than the continuous cost function for low $N$. As $N$ increases, the trajectory using the discrete cost function approaches that of the continuous cost function. This can be seen more clearly in \cref{fig:conservativeness}, where the integral of the square error is plotted against the number $N$ of B-spline basis functions up to $N=40$ for both cost functions. For these values of $N$, the plot shows an exponential convergence to the same value, with the degree of the B-spline basis functions $p$ having a small effect on the convergence.

\begin{figure}
    \centering
    \includesvg[width=\textwidth]{fig/conservativeness/compare_conservativeness_degree_3.svg}
    \caption{Comparison of the performance using the discrete and continuous cost functions. The integral of the square error is plotted against the number $N$ of B-spline basis functions for $p=3$.}
    \label{fig:conservativeness}
\end{figure}


\begin{figure}
    \centering
    \includesvg[width=\textwidth]{fig/conservativeness/compare_conservativeness_coeffs_all_degrees.svg}
    \caption{Logaritmic plot of the Integral of the square error using the discrete cost function. The value of the cost at $N=50$ is subtracted from all values in this plot to highlight the convergence.}
    \label{fig:conservativeness-coeffs}
\end{figure}

% To summarize, the discrete cost function is the best choice for the final implementation. The continuous cost function gives oscillations in the trajectory and is not able to follow the reference trajectory, even with a penalty on the second order difference of the optimization coefficients. The discrete cost function on the other hand, is able to follow the reference trajectory and does not give oscillations in the trajectory. As a drawback, the discrete cost function is more conservative than the continuous cost function for low $N$. Higher $N$, yeild diminishing returns in closing the optimality gap as the knot insertion becomes increasingly local as more knots are added.
% For a more in depth analysis of the conservativeness of B-splines, see \citet{Grimstad2016}.


% \begin{figure}
%     \centering
%     \begin{subfigure}{\textwidth}
%         \centering
%         \includesvg[width=\textwidth,pretex=\small]{fig/conservativeness/eigenvectors_integral_degree_2_N_3.svg}
%         \caption{$\mathbf H = \mathbf G$}
%     \end{subfigure}
%     \begin{subfigure}{\textwidth}
%         \centering
%         \includesvg[width=\textwidth,pretex=\small]{fig/conservativeness/eigenvectors_coeffs_degree_2_N_3.svg}
%         \caption{$\mathbf H = \mathbb{I}$}
%     \end{subfigure}
%     \begin{subfigure}{\textwidth}
%         \centering
%         \includesvg[width=\textwidth,pretex=\small]{fig/conservativeness/eigenvectors_inv_gramian_degree_2_N_3.svg}
%         \caption{$\mathbf H = \mathbf G^{-1}$}
%     \end{subfigure}
%     \caption{Eigenvectors of the Hessian of the cost function for the continuous cost function (top), discrete cost function (middle) and the inverse Gramian matrix (bottom) for $N=3$ and $p=2$.}
% \end{figure}



\begin{figure}
    \centering
    \includesvg[width=\textwidth,pretex=\small]{fig/conservativeness/eigenvectors_inv_gramian_degree_2_N_9.svg}
    \caption{Eigenvectors of the inverse Gramian matrix for $N=9$ and $p=2$.}
\end{figure}

\FloatBarrier
\subsection{COLREGS Objectives}\label{sec:colregs-objectives}
Rule 8b) of the COLREGS states that any alteration of course should be large enough to be readily apparent to another vessel. This is impractical in an optimization context as penalizing low turn rates while keeping the cost on high and no turn rates low leads to a non-convex cost. See \cref{fig:turn-rate-cost} for an illustration of the problem. 

\begin{figure}
    \centering
    \includesvg[width=0.6\textwidth]{fig/illustrations/Turn rate cost.svg}
    \caption{Imagined Turn rate cost for a vessel following Rule 8b) of the COLREGS.}
    \label{fig:turn-rate-cost}
\end{figure}

\cite{Thyri2022-MPC} proposes a solution to improve the compliance of rule 8 by introducing a time window where the cost for altering course is lowered. The goal of this is to control when the OS should alter course, and with manipulation of the length and position of the time window, the cost function can facilitate a more COLREGS compliant trajectory. This idea is adapted to the B-spline MINMPC framework as follows:
An encounter window $W_\text e$ is defined, during which the OS should ensure safe passage. Within $W_\text e$, the cost for reference trajectory following is reduced, while the cost for altering course remains high, except at the start and end of $W_\text e$, denoted as maneuver windows $W_\text{mv}$. 
The reason for the second maneuver window as opposed to the singular one in \cite{Thyri2022-MPC} is to facilitate a clear maneuver back to the reference trajectory after the encounter window.

\begin{figure}
    \centering
    \includesvg[width=0.8\textwidth]{fig/illustrations/Maneuver window.svg}
    \caption{Weights for turn rate and TTE plotted against time.}
    \label{fig:maneuver-window}
\end{figure}

The encounter window and maneuver windows enter the cost function as weights $w_\text e(x)$ and $w_\text{mv}(x)$, respectively on the reference trajectory following cost and the cost for altering course. The weights enter the cost function $O$ as
\begin{subequations}\label{eq:cost-maneuver-window}
    \begin{align}
        J_\text{mv} &= \|\text{ctrlPts}\big(w_\text{mv}(x)(\mathbf p'_\text{os}(x) - \mathbf p'_\text{ref}(x))\big)\|_\text{F}^2, \label{eq:cost-maneuver-window-mv}\\
        J_\text{ref} &= \|\text{ctrlPts}\big(w_\text e(x)(\mathbf p_\text{os}(x) - \mathbf p_\text{ref}(x))\big)\|_\text{F}^2, \label{eq:cost-maneuver-window-ref}\\
        J &= J_\text{ref} + J_\text{mv}, \label{eq:cost-maneuver-window-total}
    \end{align}
\end{subequations}
where $J_\text{mv}$ is the cost for altering course, $w_\text e(x)$ is the weight for the reference trajectory following cost, and $w_\text{mv}(x)$ is the weight for the maneuver window cost as shown in \cref{fig:maneuver-window}. Notice that $J_\text{mv}$ is defined using the Frobenius norm over the control points of the B-spline function as opposed to the definite integral over the squared reference error for the same reason as in \cref{sec:oscillations}.

The advantage of the B-spline framework in this case is that the weights can be defined as B-spline functions themselves. This allows for great flexibility in shaping the desired encounter trajectory. The function shape shown in \cref{fig:maneuver-window}, can be represented using a zero-degree B-spline. If smoother transitions are desired, higher degree B-splines can be used.
If the weights are fixed as a function of time before the optimization problem is solved, then the costs are constant with respect to the optimization variables and the optimization problem is convex as opposed to that of \cref{fig:turn-rate-cost}.

Estimating when the encounter window should start and end is a non-trivial problem. As is determining how long the maneuver windows should be. \cite{Thyri2022-MPC} proposes to use the time of closest point of approach (TCPA) to the TS along the desired trajectory. The desired trajectory can for example be estimated using Line-of-Sight (LOS) guidance \citep{Fossen2011-Handbook} or by considering the optimzation problem without the TS. Estimation of the encounter window time is implemented according to \cite{Thyri2022-MPC}, and won't be discussed further here.


\section{Implementation}\label{sec:python-implementation}

The B-spline MINMPC is implemented in python using CasADi \citep{casadi} and numpy \citep{numpy} as the main libraries. The code is divided into two main parts: a B-spline implementation and a CasAdi wrapper. 
The B-spline implementation closely follows the structure in \citet{mercy2016spline}, and takes inspiration from the CasAdi wrapper presented there. The main modifications are focused around on small optimizations, making the library more type safe, and making it easier to use with vector-valued spline functions. Support for CasADi's MIP solvers was also added, which was not present in the original implementation. 
The code is available in \todo{gh repo}.

In the end, all the B-spline transformations and handling is abstracted away, letting the user create B-spline variables and constraints on symbolic variables as if they were normal CasADi variables. 

\subsection{Optimization Problem Class}
This section will present the public interface of the Optimization Problem class. The class is designed to be used with CasADi and operates similarly to CasADi's own Opti framework. It differs from CasADi's Opti framework in that it supports B-spline variables and constraints, as well as binary and integer variables more seamlessly. The Optimization Problem class is also modular, in the sense that different objects can be used to represent e.g. the own ship, target ship and reference, before being combined into a single optimization problem. This will be clarified in the following example.

\begin{example}{Optimization Problem Setup}
\begin{python}
from cs_mpc import OptiObject, OptiCollection, BSplineBasis


degree = 3
n_control_points = 10
basis = create_uniform_b_spline_basis(
    degree, n_control_points, 0, 1
)

own_ship = OptiObject('own_ship')
os_pos = own_ship.declare_spline_variable('pos', n_dim=2, basis=basis)
os_pos_0 = own_ship.declare_parameter('pos_0', n_dim=2)
os_pos_f = own_ship.declare_parameter('pos_f', n_dim=2)

own_ship.declare_constraint(os_pos(0) - os_pos_0, lb=0, ub=0)
own_ship.declare_constraint(os_pos(1) - os_pos_f, lb=0, ub=0)

end_err = os_pos - os_pos_f
own_ship.declare_objective(end_err.dot(end_err).definite_integral(0,1))


target_ship = OptiObject('target_ship')
ts_pos = target_ship.declare_spline_parameter('pos', n_dim=2, basis=basis)
ts_err = os_pos - ts_pos
min_dist = target_ship.declare_parameter('min_dist', n_dim=1)
target_ship.declare_constraint(ts_err.dot(ts_err) - min_dist**2, lb=0)


opti = OptiCollection([own_ship, target_ship])
own_ship.set_value('pos_0', [0, 0])
own_ship.set_value('pos_f', [1000, 0])
target_ship.set_value('pos', ...)
target_ship.set_value('min_dist', 10)
sol = opti.solve()

\end{python}
\end{example}


\section{Summary}

The complete B-spline MINMPC problem can be written compactly as
\begin{equation}
\label{eq:minmpc-compact}
    \begin{aligned}
        \min
        \quad & J_\text{ref}(\mathbf{p}_\text{OS}) + J_\text{mv}(\mathbf{p}_\text{OS}) + w_\text{time}\,t(1)
        \\
        \text{subject to}\quad
        & \mathcal{D}_{DI}(\mathbf{p}_\text{OS})
        \text{ or }
        \mathcal{D}_{PH}(\mathbf{p}_\text{OS}),
        \\
        & \mathcal{O}_j\bigl(
            \mathbf{n}_{p,j}, \mathbf{n}_{s,j}, b_{p,j}, b_{s,j}, z_j
        \bigr),
        \quad &\forall j&\in \{1,\ldots,N_\text{TS}\},
    \end{aligned}
\end{equation}

In this formulation:
\begin{itemize}
    \item $J_{\mathrm{mw}}$ penalizes maneuvers outside the desired time window via weights $w_k$ on derivative norms (\cref{eq:cost-maneuver-window-mv}).
    \item $J_{\mathrm{ref}}$ penalizes deviation from the reference trajectory via the squared Frobenius norm of the B-spline coefficients (\cref{eq:cost-maneuver-window-ref}).
    \item $\mathcal{D}_{DI}$ and $\mathcal{D}_{PH}$ denote the double‐integrator and PH‐spline Dubins model constraints, respectively.
    \item $\mathcal{O}_j$ is the Big-M collision‐avoidance constraint set from \eqref{eq:colregs-bigM} for each target ship $j$ in the encounter.
    \item $w_\text{time}$ is a weight on the final time of the variable $t(x)$, which is a B-spline variable representing the time of the OS.
\end{itemize}
The optimization variables are the B-spline coefficients of the spline functions
$\mathbf{p}_\text{OS}(t)$, $t(x)$, $\mathbf{n}_{p,j}(x)$, $\mathbf{n}_{s,j}(x)$, $b_{p,j}(x)$, $b_{s,j}(x)$ defined over a suitable knot vector $\mathbf{t}\in[0,1]$, and the binary variables $z_j$.